{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-section",
   "metadata": {},
   "source": [
    "# MCP-Powered Voice Agent with DeepSeek\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the implementation of a voice-enabled AI agent that leverages:\n",
    "- **MCP (Model Context Protocol)**: For structured AI model interactions\n",
    "- **DeepSeek**: As the underlying language model for natural language processing\n",
    "- **Speech Recognition**: For converting voice input to text\n",
    "- **Text-to-Speech**: For converting AI responses back to voice\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "Voice Input ‚Üí Speech Recognition ‚Üí Text Processing ‚Üí DeepSeek Model ‚Üí MCP Protocol ‚Üí Response Generation ‚Üí Text-to-Speech ‚Üí Voice Output\n",
    "```\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Audio Processing Pipeline**: Handles voice input/output\n",
    "2. **Language Model Integration**: DeepSeek for intelligent responses\n",
    "3. **MCP Integration**: Structured communication protocol\n",
    "4. **Interactive Interface**: Jupyter widgets for user interaction\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Microphone access for voice input\n",
    "- Audio output capabilities\n",
    "- Internet connection for model downloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "This section installs and configures all necessary dependencies for the voice agent.\n",
    "\n",
    "### Widget Extensions\n",
    "We start by setting up Jupyter widgets which will provide interactive UI components for our voice agent interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widget-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and enable Jupyter widgets for interactive UI components\n",
    "# ipywidgets: Provides interactive HTML widgets for Jupyter notebooks\n",
    "# This enables buttons, sliders, and other UI elements for our voice agent interface\n",
    "\n",
    "!pip install --upgrade ipywidgets\n",
    "\n",
    "# Enable the widget extension in Jupyter\n",
    "# Note: This command may show \"not found\" in some environments but widgets will still work\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "print(\"‚úÖ Jupyter widgets setup completed\")\n",
    "print(\"üìù Note: If you see 'jupyter-nbextension not found', this is normal in some environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml-deps-section",
   "metadata": {},
   "source": [
    "### Machine Learning Dependencies\n",
    "\n",
    "Installing the core AI/ML libraries:\n",
    "- **Transformers**: Hugging Face library for pre-trained language models\n",
    "- **PyTorch**: Deep learning framework used by many modern NLP models\n",
    "- **DeepSeek Integration**: These libraries will enable us to work with DeepSeek models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core machine learning and NLP dependencies\n",
    "\n",
    "# transformers: Hugging Face library providing access to thousands of pre-trained models\n",
    "# - Includes tokenizers, model architectures, and training utilities\n",
    "# - Essential for working with modern language models like DeepSeek\n",
    "\n",
    "# torch: PyTorch deep learning framework\n",
    "# - Provides tensor operations and neural network building blocks\n",
    "# - Required backend for most transformer models\n",
    "\n",
    "!pip install transformers torch\n",
    "\n",
    "print(\"‚úÖ Machine Learning dependencies installed\")\n",
    "print(\"ü§ñ Ready to work with transformer models and DeepSeek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audio-deps-section",
   "metadata": {},
   "source": [
    "### Audio Processing Dependencies\n",
    "\n",
    "Installing libraries for voice input and output:\n",
    "- **SpeechRecognition**: Converts speech to text using various engines (Google, Sphinx, etc.)\n",
    "- **PyAudio**: Low-level audio I/O library for recording and playing audio\n",
    "- **pyttsx3**: Text-to-speech conversion library with multiple engine support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "audio-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install audio processing libraries for voice input/output\n",
    "\n",
    "# SpeechRecognition: Library for performing speech recognition\n",
    "# - Supports multiple engines: Google Speech Recognition, CMU Sphinx, etc.\n",
    "# - Handles microphone input and audio file processing\n",
    "\n",
    "# pyaudio: Cross-platform audio I/O library\n",
    "# - Provides low-level access to audio hardware\n",
    "# - Required for real-time audio recording and playback\n",
    "\n",
    "# pyttsx3: Text-to-speech conversion library\n",
    "# - Works offline with system TTS engines\n",
    "# - Cross-platform support (Windows SAPI, macOS NSSpeechSynthesizer, Linux espeak)\n",
    "\n",
    "!pip install SpeechRecognition pyaudio pyttsx3\n",
    "\n",
    "print(\"‚úÖ Audio processing dependencies installed\")\n",
    "print(\"üé§ Speech recognition ready\")\n",
    "print(\"üîä Text-to-speech ready\")\n",
    "print(\"‚ö†Ô∏è  Note: If PyAudio installation fails, you may need system audio development libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "additional-deps-section",
   "metadata": {},
   "source": [
    "### Additional Dependencies for MCP and Enhanced Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "additional-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies for enhanced functionality\n",
    "\n",
    "# requests: HTTP library for API calls (DeepSeek API integration)\n",
    "# openai: Client library for OpenAI-compatible APIs (DeepSeek supports OpenAI format)\n",
    "# asyncio: Asynchronous programming support for non-blocking operations\n",
    "# json: Built-in JSON handling (usually pre-installed)\n",
    "# threading: Built-in threading support for concurrent operations\n",
    "\n",
    "!pip install requests openai aiohttp\n",
    "\n",
    "print(\"‚úÖ Additional dependencies installed\")\n",
    "print(\"üåê API integration ready\")\n",
    "print(\"‚ö° Async operations supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Initialize Components\n",
    "\n",
    "This section imports all necessary libraries and sets up the basic components for our voice agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import asyncio\n",
    "from typing import Dict, List, Optional, Any\n",
    "import logging\n",
    "\n",
    "# Audio processing libraries\n",
    "import speech_recognition as sr  # Speech-to-text conversion\n",
    "import pyttsx3                   # Text-to-speech conversion\n",
    "import pyaudio                   # Audio I/O operations\n",
    "\n",
    "# Machine learning and NLP libraries\n",
    "import torch                     # PyTorch deep learning framework\n",
    "from transformers import (\n",
    "    AutoTokenizer,               # Automatic tokenizer selection\n",
    "    AutoModelForCausalLM,        # Causal language model (GPT-style)\n",
    "    pipeline                     # High-level model interface\n",
    ")\n",
    "\n",
    "# HTTP and API libraries\n",
    "import requests                  # HTTP requests for API calls\n",
    "from openai import OpenAI        # OpenAI-compatible client for DeepSeek\n",
    "\n",
    "# Jupyter notebook libraries\n",
    "import ipywidgets as widgets     # Interactive widgets\n",
    "from IPython.display import display, clear_output, HTML, Audio\n",
    "\n",
    "# Configure logging for debugging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(\"üì¶ Core components ready for initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-section",
   "metadata": {},
   "source": [
    "## 3. Configuration and Environment Variables\n",
    "\n",
    "Setting up configuration parameters and environment variables for the voice agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration class for voice agent settings\n",
    "class VoiceAgentConfig:\n",
    "    \"\"\"\n",
    "    Configuration class containing all settings for the voice agent.\n",
    "    \n",
    "    This centralized configuration makes it easy to adjust parameters\n",
    "    without modifying code throughout the notebook.\n",
    "    \"\"\"\n",
    "    \n",
    "    # API Configuration\n",
    "    DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\", \"your-deepseek-api-key-here\")\n",
    "    DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"  # DeepSeek API endpoint\n",
    "    \n",
    "    # Model Configuration\n",
    "    MODEL_NAME = \"deepseek-chat\"  # DeepSeek model identifier\n",
    "    MAX_TOKENS = 1000             # Maximum tokens in response\n",
    "    TEMPERATURE = 0.7             # Response creativity (0.0-1.0)\n",
    "    \n",
    "    # Audio Configuration\n",
    "    SAMPLE_RATE = 16000          # Audio sample rate (Hz)\n",
    "    CHUNK_SIZE = 1024            # Audio chunk size for processing\n",
    "    AUDIO_FORMAT = pyaudio.paInt16  # Audio format (16-bit)\n",
    "    CHANNELS = 1                 # Mono audio\n",
    "    \n",
    "    # Speech Recognition Configuration\n",
    "    RECOGNITION_TIMEOUT = 5      # Timeout for speech recognition (seconds)\n",
    "    PHRASE_TIMEOUT = 1           # Timeout between phrases (seconds)\n",
    "    ENERGY_THRESHOLD = 300       # Minimum audio energy for speech detection\n",
    "    \n",
    "    # Text-to-Speech Configuration\n",
    "    TTS_RATE = 200              # Speech rate (words per minute)\n",
    "    TTS_VOLUME = 0.9            # Speech volume (0.0-1.0)\n",
    "    TTS_VOICE_INDEX = 0         # Voice selection index\n",
    "    \n",
    "    # MCP Configuration\n",
    "    MCP_VERSION = \"1.0\"         # MCP protocol version\n",
    "    MCP_TIMEOUT = 30            # MCP operation timeout (seconds)\n",
    "\n",
    "# Initialize configuration\n",
    "config = VoiceAgentConfig()\n",
    "\n",
    "print(\"‚úÖ Configuration initialized\")\n",
    "print(f\"üîë DeepSeek API configured: {'‚úì' if config.DEEPSEEK_API_KEY != 'your-deepseek-api-key-here' else '‚úó (Please set DEEPSEEK_API_KEY)'}\")\n",
    "print(f\"üéØ Model: {config.MODEL_NAME}\")\n",
    "print(f\"üé§ Audio sample rate: {config.SAMPLE_RATE} Hz\")\n",
    "print(f\"üîä TTS rate: {config.TTS_RATE} WPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-section",
   "metadata": {},
   "source": [
    "## 4. MCP (Model Context Protocol) Implementation\n",
    "\n",
    "The Model Context Protocol provides a structured way to interact with AI models, ensuring consistent communication and context management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcp-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPProtocol:\n",
    "    \"\"\"\n",
    "    Model Context Protocol implementation for structured AI interactions.\n",
    "    \n",
    "    MCP provides a standardized way to:\n",
    "    - Manage conversation context\n",
    "    - Handle model requests and responses\n",
    "    - Maintain session state\n",
    "    - Ensure consistent communication format\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: VoiceAgentConfig):\n",
    "        \"\"\"\n",
    "        Initialize MCP protocol handler.\n",
    "        \n",
    "        Args:\n",
    "            config: Voice agent configuration object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.session_id = f\"session_{int(time.time())}\"\n",
    "        self.context_history = []  # Conversation history\n",
    "        self.metadata = {          # Session metadata\n",
    "            \"version\": config.MCP_VERSION,\n",
    "            \"created_at\": time.time(),\n",
    "            \"model\": config.MODEL_NAME\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"MCP Protocol initialized - Session: {self.session_id}\")\n",
    "    \n",
    "    def create_request(self, user_input: str, context: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Create a structured MCP request.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's text input\n",
    "            context: Additional context information\n",
    "            \n",
    "        Returns:\n",
    "            Structured MCP request dictionary\n",
    "        \"\"\"\n",
    "        request = {\n",
    "            \"mcp_version\": self.config.MCP_VERSION,\n",
    "            \"session_id\": self.session_id,\n",
    "            \"timestamp\": time.time(),\n",
    "            \"request_id\": f\"req_{len(self.context_history)}\",\n",
    "            \"user_input\": user_input,\n",
    "            \"context\": context or {},\n",
    "            \"history\": self.context_history[-5:],  # Last 5 interactions\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"MCP request created: {request['request_id']}\")\n",
    "        return request\n",
    "    \n",
    "    def process_response(self, response: str, request_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process and structure an MCP response.\n",
    "        \n",
    "        Args:\n",
    "            response: Model's response text\n",
    "            request_id: ID of the original request\n",
    "            \n",
    "        Returns:\n",
    "            Structured MCP response dictionary\n",
    "        \"\"\"\n",
    "        response_data = {\n",
    "            \"mcp_version\": self.config.MCP_VERSION,\n",
    "            \"session_id\": self.session_id,\n",
    "            \"timestamp\": time.time(),\n",
    "            \"request_id\": request_id,\n",
    "            \"response\": response,\n",
    "            \"status\": \"success\",\n",
    "            \"metadata\": {\n",
    "                \"model\": self.config.MODEL_NAME,\n",
    "                \"tokens_used\": len(response.split()),  # Approximate\n",
    "                \"processing_time\": 0  # Will be calculated by caller\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add to context history\n",
    "        self.context_history.append({\n",
    "            \"request_id\": request_id,\n",
    "            \"timestamp\": response_data[\"timestamp\"],\n",
    "            \"response\": response\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"MCP response processed: {request_id}\")\n",
    "        return response_data\n",
    "    \n",
    "    def get_context_summary(self) -> str:\n",
    "        \"\"\"\n",
    "        Get a summary of the current conversation context.\n",
    "        \n",
    "        Returns:\n",
    "            String summary of conversation context\n",
    "        \"\"\"\n",
    "        if not self.context_history:\n",
    "            return \"No previous conversation context.\"\n",
    "        \n",
    "        summary = f\"Conversation with {len(self.context_history)} previous interactions:\\n\"\n",
    "        for i, interaction in enumerate(self.context_history[-3:], 1):\n",
    "            summary += f\"{i}. {interaction['response'][:100]}...\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize MCP protocol\n",
    "mcp = MCPProtocol(config)\n",
    "\n",
    "print(\"‚úÖ MCP Protocol initialized\")\n",
    "print(f\"üÜî Session ID: {mcp.session_id}\")\n",
    "print(f\"üìã Context tracking: Active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deepseek-section",
   "metadata": {},
   "source": [
    "## 5. DeepSeek Model Integration\n",
    "\n",
    "This section implements the integration with DeepSeek's language model API, providing the core AI capabilities for our voice agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deepseek-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSeekClient:\n",
    "    \"\"\"\n",
    "    DeepSeek API client for language model interactions.\n",
    "    \n",
    "    This client handles:\n",
    "    - API authentication and requests\n",
    "    - Response processing and error handling\n",
    "    - Context management for conversations\n",
    "    - Rate limiting and retry logic\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: VoiceAgentConfig):\n",
    "        \"\"\"\n",
    "        Initialize DeepSeek client.\n",
    "        \n",
    "        Args:\n",
    "            config: Voice agent configuration object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize OpenAI-compatible client for DeepSeek\n",
    "        self.client = OpenAI(\n",
    "            api_key=config.DEEPSEEK_API_KEY,\n",
    "            base_url=config.DEEPSEEK_BASE_URL\n",
    "        )\n",
    "        \n",
    "        # System prompt for voice agent behavior\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a helpful voice assistant powered by DeepSeek. You should:\n",
    "        - Provide clear, concise responses suitable for speech\n",
    "        - Be conversational and friendly\n",
    "        - Ask clarifying questions when needed\n",
    "        - Keep responses under 200 words for better voice experience\n",
    "        - Use natural language without excessive technical jargon\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        logger.info(\"DeepSeek client initialized\")\n",
    "    \n",
    "    async def generate_response(self, user_input: str, context: Optional[List[Dict]] = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate a response using the DeepSeek model.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's text input\n",
    "            context: Previous conversation context\n",
    "            \n",
    "        Returns:\n",
    "            Generated response text\n",
    "            \n",
    "        Raises:\n",
    "            Exception: If API call fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prepare messages for the API\n",
    "            messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "            \n",
    "            # Add conversation context if available\n",
    "            if context:\n",
    "                for item in context:\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": item[\"response\"]})\n",
    "            \n",
    "            # Add current user input\n",
    "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "            \n",
    "            logger.info(f\"Sending request to DeepSeek: {len(user_input)} characters\")\n",
    "            \n",
    "            # Make API call\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.MODEL_NAME,\n",
    "                messages=messages,\n",
    "                max_tokens=self.config.MAX_TOKENS,\n",
    "                temperature=self.config.TEMPERATURE,\n",
    "                stream=False\n",
    "            )\n",
    "            \n",
    "            # Extract response text\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            logger.info(f\"DeepSeek response received: {len(response_text)} characters\")\n",
    "            return response_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"DeepSeek API error: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return f\"I'm sorry, I'm having trouble processing your request right now. Error: {str(e)}\"\n",
    "    \n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"\n",
    "        Test the connection to DeepSeek API.\n",
    "        \n",
    "        Returns:\n",
    "            True if connection successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Simple test request\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                max_tokens=10\n",
    "            )\n",
    "            \n",
    "            logger.info(\"DeepSeek API connection test successful\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"DeepSeek API connection test failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Initialize DeepSeek client\n",
    "deepseek_client = DeepSeekClient(config)\n",
    "\n",
    "print(\"‚úÖ DeepSeek client initialized\")\n",
    "print(f\"üåê API endpoint: {config.DEEPSEEK_BASE_URL}\")\n",
    "print(f\"ü§ñ Model: {config.MODEL_NAME}\")\n",
    "\n",
    "# Test API connection (optional)\n",
    "if config.DEEPSEEK_API_KEY != \"your-deepseek-api-key-here\":\n",
    "    print(\"üîç Testing API connection...\")\n",
    "    connection_status = deepseek_client.test_connection()\n",
    "    print(f\"üîó API Connection: {'‚úÖ Success' if connection_status else '‚ùå Failed'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  API key not configured - set DEEPSEEK_API_KEY environment variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audio-section",
   "metadata": {},
   "source": [
    "## 6. Audio Processing Components\n",
    "\n",
    "This section implements the speech recognition and text-to-speech components that enable voice interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "audio-components",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    \"\"\"\n",
    "    Audio processing class handling speech recognition and text-to-speech.\n",
    "    \n",
    "    This class manages:\n",
    "    - Microphone input and audio recording\n",
    "    - Speech-to-text conversion using Google Speech Recognition\n",
    "    - Text-to-speech output using system TTS engines\n",
    "    - Audio device configuration and error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: VoiceAgentConfig):\n",
    "        \"\"\"\n",
    "        Initialize audio processor.\n",
    "        \n",
    "        Args:\n",
    "            config: Voice agent configuration object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize speech recognition\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.microphone = sr.Microphone()\n",
    "        \n",
    "        # Configure recognizer settings\n",
    "        self.recognizer.energy_threshold = config.ENERGY_THRESHOLD\n",
    "        self.recognizer.dynamic_energy_threshold = True\n",
    "        self.recognizer.pause_threshold = config.PHRASE_TIMEOUT\n",
    "        \n",
    "        # Initialize text-to-speech\n",
    "        self.tts_engine = pyttsx3.init()\n",
    "        \n",
    "        # Configure TTS settings\n",
    "        self.tts_engine.setProperty('rate', config.TTS_RATE)\n",
    "        self.tts_engine.setProperty('volume', config.TTS_VOLUME)\n",
    "        \n",
    "        # Set voice if available\n",
    "        voices = self.tts_engine.getProperty('voices')\n",
    "        if voices and len(voices) > config.TTS_VOICE_INDEX:\n",
    "            self.tts_engine.setProperty('voice', voices[config.TTS_VOICE_INDEX].id)\n",
    "        \n",
    "        # Calibrate microphone for ambient noise\n",
    "        self._calibrate_microphone()\n",
    "        \n",
    "        logger.info(\"Audio processor initialized\")\n",
    "    \n",
    "    def _calibrate_microphone(self):\n",
    "        \"\"\"\n",
    "        Calibrate microphone for ambient noise levels.\n",
    "        \n",
    "        This helps improve speech recognition accuracy by adjusting\n",
    "        the energy threshold based on background noise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.microphone as source:\n",
    "                logger.info(\"Calibrating microphone for ambient noise...\")\n",
    "                self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "                logger.info(f\"Microphone calibrated - Energy threshold: {self.recognizer.energy_threshold}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Microphone calibration failed: {str(e)}\")\n",
    "    \n",
    "    def listen_for_speech(self, timeout: Optional[float] = None) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Listen for speech input and convert to text.\n",
    "        \n",
    "        Args:\n",
    "            timeout: Maximum time to wait for speech (seconds)\n",
    "            \n",
    "        Returns:\n",
    "            Recognized speech text or None if recognition failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Listening for speech...\")\n",
    "            \n",
    "            with self.microphone as source:\n",
    "                # Listen for audio with timeout\n",
    "                audio = self.recognizer.listen(\n",
    "                    source, \n",
    "                    timeout=timeout or self.config.RECOGNITION_TIMEOUT,\n",
    "                    phrase_time_limit=5\n",
    "                )\n",
    "            \n",
    "            logger.info(\"Processing speech...\")\n",
    "            \n",
    "            # Recognize speech using Google Speech Recognition\n",
    "            text = self.recognizer.recognize_google(audio)\n",
    "            \n",
    "            logger.info(f\"Speech recognized: '{text}'\")\n",
    "            return text\n",
    "            \n",
    "        except sr.WaitTimeoutError:\n",
    "            logger.warning(\"Speech recognition timeout\")\n",
    "            return None\n",
    "        except sr.UnknownValueError:\n",
    "            logger.warning(\"Could not understand speech\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            logger.error(f\"Speech recognition service error: {str(e)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error in speech recognition: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def speak_text(self, text: str) -> bool:\n",
    "        \"\"\"\n",
    "        Convert text to speech and play it.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to convert to speech\n",
    "            \n",
    "        Returns:\n",
    "            True if speech synthesis successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Speaking text: '{text[:50]}...'\")\n",
    "            \n",
    "            # Use text-to-speech engine\n",
    "            self.tts_engine.say(text)\n",
    "            self.tts_engine.runAndWait()\n",
    "            \n",
    "            logger.info(\"Text-to-speech completed\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Text-to-speech error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def test_audio_devices(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test audio input and output devices.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with test results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"microphone\": False,\n",
    "            \"speakers\": False,\n",
    "            \"details\": {}\n",
    "        }\n",
    "        \n",
    "        # Test microphone\n",
    "        try:\n",
    "            with self.microphone as source:\n",
    "                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "            results[\"microphone\"] = True\n",
    "            results[\"details\"][\"microphone\"] = \"Working\"\n",
    "        except Exception as e:\n",
    "            results[\"details\"][\"microphone\"] = f\"Error: {str(e)}\"\n",
    "        \n",
    "        # Test speakers/TTS\n",
    "        try:\n",
    "            self.tts_engine.say(\"Audio test\")\n",
    "            self.tts_engine.runAndWait()\n",
    "            results[\"speakers\"] = True\n",
    "            results[\"details\"][\"speakers\"] = \"Working\"\n",
    "        except Exception as e:\n",
    "            results[\"details\"][\"speakers\"] = f\"Error: {str(e)}\"\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize audio processor\n",
    "audio_processor = AudioProcessor(config)\n",
    "\n",
    "print(\"‚úÖ Audio processor initialized\")\n",
    "print(f\"üé§ Energy threshold: {audio_processor.recognizer.energy_threshold}\")\n",
    "print(f\"üîä TTS rate: {config.TTS_RATE} WPM\")\n",
    "\n",
    "# Test audio devices\n",
    "print(\"üîç Testing audio devices...\")\n",
    "audio_test = audio_processor.test_audio_devices()\n",
    "print(f\"üé§ Microphone: {'‚úÖ' if audio_test['microphone'] else '‚ùå'} {audio_test['details']['microphone']}\")\n",
    "print(f\"üîä Speakers: {'‚úÖ' if audio_test['speakers'] else '‚ùå'} {audio_test['details']['speakers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voice-agent-section",
   "metadata": {},
   "source": [
    "## 7. Voice Agent Core Implementation\n",
    "\n",
    "This section implements the main voice agent class that orchestrates all components to provide a complete voice interaction experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voice-agent-core",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceAgent:\n",
    "    \"\"\"\n",
    "    Main voice agent class that orchestrates all components.\n",
    "    \n",
    "    This class integrates:\n",
    "    - Audio processing (speech recognition and TTS)\n",
    "    - MCP protocol for structured interactions\n",
    "    - DeepSeek model for AI responses\n",
    "    - Session management and conversation flow\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: VoiceAgentConfig, mcp: MCPProtocol, \n",
    "                 deepseek_client: DeepSeekClient, audio_processor: AudioProcessor):\n",
    "        \"\"\"\n",
    "        Initialize the voice agent.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object\n",
    "            mcp: MCP protocol handler\n",
    "            deepseek_client: DeepSeek API client\n",
    "            audio_processor: Audio processing handler\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.mcp = mcp\n",
    "        self.deepseek_client = deepseek_client\n",
    "        self.audio_processor = audio_processor\n",
    "        \n",
    "        # Agent state\n",
    "        self.is_listening = False\n",
    "        self.conversation_active = False\n",
    "        self.stats = {\n",
    "            \"interactions\": 0,\n",
    "            \"successful_recognitions\": 0,\n",
    "            \"failed_recognitions\": 0,\n",
    "            \"responses_generated\": 0,\n",
    "            \"start_time\": time.time()\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Voice agent initialized\")\n",
    "    \n",
    "    async def process_voice_interaction(self, timeout: Optional[float] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a complete voice interaction cycle.\n",
    "        \n",
    "        This method handles the full workflow:\n",
    "        1. Listen for speech input\n",
    "        2. Convert speech to text\n",
    "        3. Generate AI response using DeepSeek\n",
    "        4. Convert response to speech\n",
    "        5. Update conversation context\n",
    "        \n",
    "        Args:\n",
    "            timeout: Maximum time to wait for speech input\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing interaction results\n",
    "        \"\"\"\n",
    "        interaction_start = time.time()\n",
    "        result = {\n",
    "            \"success\": False,\n",
    "            \"user_input\": None,\n",
    "            \"ai_response\": None,\n",
    "            \"error\": None,\n",
    "            \"processing_time\": 0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            logger.info(\"Starting voice interaction cycle\")\n",
    "            self.stats[\"interactions\"] += 1\n",
    "            \n",
    "            # Step 1: Listen for speech input\n",
    "            logger.info(\"üé§ Listening for speech...\")\n",
    "            user_input = self.audio_processor.listen_for_speech(timeout)\n",
    "            \n",
    "            if not user_input:\n",
    "                result[\"error\"] = \"No speech detected or recognition failed\"\n",
    "                self.stats[\"failed_recognitions\"] += 1\n",
    "                return result\n",
    "            \n",
    "            result[\"user_input\"] = user_input\n",
    "            self.stats[\"successful_recognitions\"] += 1\n",
    "            logger.info(f\"‚úÖ Speech recognized: '{user_input}'\")\n",
    "            \n",
    "            # Step 2: Create MCP request\n",
    "            mcp_request = self.mcp.create_request(user_input)\n",
    "            \n",
    "            # Step 3: Generate AI response using DeepSeek\n",
    "            logger.info(\"ü§ñ Generating AI response...\")\n",
    "            ai_response = await self.deepseek_client.generate_response(\n",
    "                user_input, \n",
    "                self.mcp.context_history\n",
    "            )\n",
    "            \n",
    "            result[\"ai_response\"] = ai_response\n",
    "            self.stats[\"responses_generated\"] += 1\n",
    "            logger.info(f\"‚úÖ AI response generated: '{ai_response[:100]}...'\")\n",
    "            \n",
    "            # Step 4: Process MCP response\n",
    "            mcp_response = self.mcp.process_response(ai_response, mcp_request[\"request_id\"])\n",
    "            \n",
    "            # Step 5: Convert response to speech\n",
    "            logger.info(\"üîä Converting response to speech...\")\n",
    "            speech_success = self.audio_processor.speak_text(ai_response)\n",
    "            \n",
    "            if not speech_success:\n",
    "                logger.warning(\"Text-to-speech failed, but interaction was successful\")\n",
    "            \n",
    "            result[\"success\"] = True\n",
    "            result[\"processing_time\"] = time.time() - interaction_start\n",
    "            \n",
    "            logger.info(f\"‚úÖ Voice interaction completed in {result['processing_time']:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            result[\"error\"] = str(e)\n",
    "            result[\"processing_time\"] = time.time() - interaction_start\n",
    "            logger.error(f\"Voice interaction failed: {str(e)}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    async def start_conversation_mode(self, max_interactions: int = 10):\n",
    "        \"\"\"\n",
    "        Start continuous conversation mode.\n",
    "        \n",
    "        Args:\n",
    "            max_interactions: Maximum number of interactions before stopping\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting conversation mode (max {max_interactions} interactions)\")\n",
    "        self.conversation_active = True\n",
    "        \n",
    "        # Welcome message\n",
    "        welcome_msg = \"Hello! I'm your voice assistant. How can I help you today?\"\n",
    "        print(f\"ü§ñ Assistant: {welcome_msg}\")\n",
    "        self.audio_processor.speak_text(welcome_msg)\n",
    "        \n",
    "        interaction_count = 0\n",
    "        \n",
    "        while self.conversation_active and interaction_count < max_interactions:\n",
    "            try:\n",
    "                print(f\"\\n--- Interaction {interaction_count + 1} ---\")\n",
    "                print(\"üé§ Listening... (Speak now or wait for timeout)\")\n",
    "                \n",
    "                # Process voice interaction\n",
    "                result = await self.process_voice_interaction(timeout=10)\n",
    "                \n",
    "                if result[\"success\"]:\n",
    "                    print(f\"üë§ You: {result['user_input']}\")\n",
    "                    print(f\"ü§ñ Assistant: {result['ai_response']}\")\n",
    "                    print(f\"‚è±Ô∏è  Processing time: {result['processing_time']:.2f}s\")\n",
    "                    \n",
    "                    # Check for exit commands\n",
    "                    if any(word in result[\"user_input\"].lower() for word in [\"goodbye\", \"bye\", \"exit\", \"quit\", \"stop\"]):\n",
    "                        farewell = \"Goodbye! It was nice talking with you.\"\n",
    "                        print(f\"ü§ñ Assistant: {farewell}\")\n",
    "                        self.audio_processor.speak_text(farewell)\n",
    "                        break\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"‚ùå Interaction failed: {result['error']}\")\n",
    "                    \n",
    "                    # Give user feedback\n",
    "                    if \"No speech detected\" in str(result['error']):\n",
    "                        feedback = \"I didn't hear anything. Try speaking a bit louder.\"\n",
    "                    else:\n",
    "                        feedback = \"Sorry, I had trouble understanding. Could you try again?\"\n",
    "                    \n",
    "                    print(f\"ü§ñ Assistant: {feedback}\")\n",
    "                    self.audio_processor.speak_text(feedback)\n",
    "                \n",
    "                interaction_count += 1\n",
    "                \n",
    "                # Brief pause between interactions\n",
    "                await asyncio.sleep(1)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nüõë Conversation interrupted by user\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unexpected error in conversation mode: {str(e)}\")\n",
    "                print(f\"‚ùå Unexpected error: {str(e)}\")\n",
    "                break\n",
    "        \n",
    "        self.conversation_active = False\n",
    "        logger.info(\"Conversation mode ended\")\n",
    "    \n",
    "    def get_session_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get session statistics.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing session statistics\n",
    "        \"\"\"\n",
    "        runtime = time.time() - self.stats[\"start_time\"]\n",
    "        \n",
    "        return {\n",
    "            \"session_id\": self.mcp.session_id,\n",
    "            \"runtime_seconds\": runtime,\n",
    "            \"total_interactions\": self.stats[\"interactions\"],\n",
    "            \"successful_recognitions\": self.stats[\"successful_recognitions\"],\n",
    "            \"failed_recognitions\": self.stats[\"failed_recognitions\"],\n",
    "            \"recognition_success_rate\": (\n",
    "                self.stats[\"successful_recognitions\"] / max(1, self.stats[\"interactions\"]) * 100\n",
    "            ),\n",
    "            \"responses_generated\": self.stats[\"responses_generated\"],\n",
    "            \"context_history_size\": len(self.mcp.context_history)\n",
    "        }\n",
    "    \n",
    "    def stop_conversation(self):\n",
    "        \"\"\"Stop the current conversation.\"\"\"\n",
    "        self.conversation_active = False\n",
    "        logger.info(\"Conversation stopped by user\")\n",
    "\n",
    "# Initialize voice agent\n",
    "voice_agent = VoiceAgent(config, mcp, deepseek_client, audio_processor)\n",
    "\n",
    "print(\"‚úÖ Voice Agent initialized\")\n",
    "print(f\"üÜî Session: {voice_agent.mcp.session_id}\")\n",
    "print(\"üéØ Ready for voice interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ui-section",
   "metadata": {},
   "source": [
    "## 8. Interactive User Interface\n",
    "\n",
    "This section creates an interactive Jupyter widget interface for controlling the voice agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interactive-ui",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceAgentUI:\n",
    "    \"\"\"\n",
    "    Interactive user interface for the voice agent using Jupyter widgets.\n",
    "    \n",
    "    This class provides:\n",
    "    - Control buttons for starting/stopping conversations\n",
    "    - Real-time status updates\n",
    "    - Session statistics display\n",
    "    - Configuration controls\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, voice_agent: VoiceAgent):\n",
    "        \"\"\"\n",
    "        Initialize the UI components.\n",
    "        \n",
    "        Args:\n",
    "            voice_agent: Voice agent instance to control\n",
    "        \"\"\"\n",
    "        self.voice_agent = voice_agent\n",
    "        self.setup_widgets()\n",
    "        self.setup_event_handlers()\n",
    "    \n",
    "    def setup_widgets(self):\n",
    "        \"\"\"\n",
    "        Create all UI widgets.\n",
    "        \"\"\"\n",
    "        # Control buttons\n",
    "        self.start_button = widgets.Button(\n",
    "            description=\"üé§ Start Conversation\",\n",
    "            button_style=\"success\",\n",
    "            layout=widgets.Layout(width=\"200px\", height=\"40px\")\n",
    "        )\n",
    "        \n",
    "        self.stop_button = widgets.Button(\n",
    "            description=\"üõë Stop Conversation\",\n",
    "            button_style=\"danger\",\n",
    "            layout=widgets.Layout(width=\"200px\", height=\"40px\"),\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        self.single_interaction_button = widgets.Button(\n",
    "            description=\"üéØ Single Interaction\",\n",
    "            button_style=\"info\",\n",
    "            layout=widgets.Layout(width=\"200px\", height=\"40px\")\n",
    "        )\n",
    "        \n",
    "        # Status display\n",
    "        self.status_output = widgets.Output()\n",
    "        \n",
    "        # Configuration controls\n",
    "        self.max_interactions_slider = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=1,\n",
    "            max=50,\n",
    "            description=\"Max Interactions:\",\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.timeout_slider = widgets.FloatSlider(\n",
    "            value=10.0,\n",
    "            min=5.0,\n",
    "            max=30.0,\n",
    "            step=1.0,\n",
    "            description=\"Listen Timeout (s):\",\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Statistics display\n",
    "        self.stats_output = widgets.Output()\n",
    "        \n",
    "        # Layout containers\n",
    "        self.control_box = widgets.HBox([\n",
    "            self.start_button,\n",
    "            self.stop_button,\n",
    "            self.single_interaction_button\n",
    "        ])\n",
    "        \n",
    "        self.config_box = widgets.VBox([\n",
    "            self.max_interactions_slider,\n",
    "            self.timeout_slider\n",
    "        ])\n",
    "        \n",
    "        self.main_container = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>üé§ Voice Agent Control Panel</h3>\"),\n",
    "            self.control_box,\n",
    "            widgets.HTML(\"<h4>‚öôÔ∏è Configuration</h4>\"),\n",
    "            self.config_box,\n",
    "            widgets.HTML(\"<h4>üìä Status</h4>\"),\n",
    "            self.status_output,\n",
    "            widgets.HTML(\"<h4>üìà Statistics</h4>\"),\n",
    "            self.stats_output\n",
    "        ])\n",
    "    \n",
    "    def setup_event_handlers(self):\n",
    "        \"\"\"\n",
    "        Set up event handlers for widget interactions.\n",
    "        \"\"\"\n",
    "        self.start_button.on_click(self.on_start_conversation)\n",
    "        self.stop_button.on_click(self.on_stop_conversation)\n",
    "        self.single_interaction_button.on_click(self.on_single_interaction)\n",
    "    \n",
    "    def on_start_conversation(self, button):\n",
    "        \"\"\"\n",
    "        Handle start conversation button click.\n",
    "        \"\"\"\n",
    "        self.start_button.disabled = True\n",
    "        self.stop_button.disabled = False\n",
    "        self.single_interaction_button.disabled = True\n",
    "        \n",
    "        with self.status_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üöÄ Starting conversation mode...\")\n",
    "            print(\"üí° Say 'goodbye', 'bye', 'exit', 'quit', or 'stop' to end the conversation\")\n",
    "        \n",
    "        # Start conversation in background\n",
    "        asyncio.create_task(self.run_conversation())\n",
    "    \n",
    "    def on_stop_conversation(self, button):\n",
    "        \"\"\"\n",
    "        Handle stop conversation button click.\n",
    "        \"\"\"\n",
    "        self.voice_agent.stop_conversation()\n",
    "        self.reset_buttons()\n",
    "        \n",
    "        with self.status_output:\n",
    "            print(\"üõë Conversation stopped by user\")\n",
    "    \n",
    "    def on_single_interaction(self, button):\n",
    "        \"\"\"\n",
    "        Handle single interaction button click.\n",
    "        \"\"\"\n",
    "        self.single_interaction_button.disabled = True\n",
    "        \n",
    "        with self.status_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üéØ Starting single interaction...\")\n",
    "            print(\"üé§ Speak now!\")\n",
    "        \n",
    "        # Start single interaction in background\n",
    "        asyncio.create_task(self.run_single_interaction())\n",
    "    \n",
    "    async def run_conversation(self):\n",
    "        \"\"\"\n",
    "        Run the conversation mode asynchronously.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            await self.voice_agent.start_conversation_mode(\n",
    "                max_interactions=self.max_interactions_slider.value\n",
    "            )\n",
    "        except Exception as e:\n",
    "            with self.status_output:\n",
    "                print(f\"‚ùå Error in conversation mode: {str(e)}\")\n",
    "        finally:\n",
    "            self.reset_buttons()\n",
    "            self.update_stats()\n",
    "    \n",
    "    async def run_single_interaction(self):\n",
    "        \"\"\"\n",
    "        Run a single interaction asynchronously.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = await self.voice_agent.process_voice_interaction(\n",
    "                timeout=self.timeout_slider.value\n",
    "            )\n",
    "            \n",
    "            with self.status_output:\n",
    "                if result[\"success\"]:\n",
    "                    print(f\"‚úÖ Interaction successful!\")\n",
    "                    print(f\"üë§ You said: {result['user_input']}\")\n",
    "                    print(f\"ü§ñ Assistant responded: {result['ai_response']}\")\n",
    "                    print(f\"‚è±Ô∏è  Processing time: {result['processing_time']:.2f}s\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Interaction failed: {result['error']}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            with self.status_output:\n",
    "                print(f\"‚ùå Error in single interaction: {str(e)}\")\n",
    "        finally:\n",
    "            self.single_interaction_button.disabled = False\n",
    "            self.update_stats()\n",
    "    \n",
    "    def reset_buttons(self):\n",
    "        \"\"\"\n",
    "        Reset button states to default.\n",
    "        \"\"\"\n",
    "        self.start_button.disabled = False\n",
    "        self.stop_button.disabled = True\n",
    "        self.single_interaction_button.disabled = False\n",
    "    \n",
    "    def update_stats(self):\n",
    "        \"\"\"\n",
    "        Update the statistics display.\n",
    "        \"\"\"\n",
    "        stats = self.voice_agent.get_session_stats()\n",
    "        \n",
    "        with self.stats_output:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"üìä Session Statistics:\")\n",
    "            print(f\"  üÜî Session ID: {stats['session_id']}\")\n",
    "            print(f\"  ‚è∞ Runtime: {stats['runtime_seconds']:.1f} seconds\")\n",
    "            print(f\"  üí¨ Total Interactions: {stats['total_interactions']}\")\n",
    "            print(f\"  ‚úÖ Successful Recognitions: {stats['successful_recognitions']}\")\n",
    "            print(f\"  ‚ùå Failed Recognitions: {stats['failed_recognitions']}\")\n",
    "            print(f\"  üìà Recognition Success Rate: {stats['recognition_success_rate']:.1f}%\")\n",
    "            print(f\"  ü§ñ Responses Generated: {stats['responses_generated']}\")\n",
    "            print(f\"  üìù Context History Size: {stats['context_history_size']}\")\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"\n",
    "        Display the UI.\n",
    "        \"\"\"\n",
    "        # Initial status update\n",
    "        with self.status_output:\n",
    "            print(\"‚úÖ Voice Agent ready!\")\n",
    "            print(\"üí° Click 'Start Conversation' for continuous mode or 'Single Interaction' for one-time use\")\n",
    "        \n",
    "        # Initial stats update\n",
    "        self.update_stats()\n",
    "        \n",
    "        # Display the main container\n",
    "        display(self.main_container)\n",
    "\n",
    "# Initialize and display UI\n",
    "ui = VoiceAgentUI(voice_agent)\n",
    "ui.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-section",
   "metadata": {},
   "source": [
    "## 9. Testing and Troubleshooting\n",
    "\n",
    "This section provides comprehensive testing utilities and troubleshooting guides for common issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "testing-utilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceAgentTester:\n",
    "    \"\"\"\n",
    "    Comprehensive testing utilities for the voice agent.\n",
    "    \n",
    "    This class provides methods to test:\n",
    "    - Individual components (audio, API, MCP)\n",
    "    - Integration between components\n",
    "    - Performance benchmarks\n",
    "    - Error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, voice_agent: VoiceAgent):\n",
    "        \"\"\"\n",
    "        Initialize the tester.\n",
    "        \n",
    "        Args:\n",
    "            voice_agent: Voice agent instance to test\n",
    "        \"\"\"\n",
    "        self.voice_agent = voice_agent\n",
    "        self.test_results = {}\n",
    "    \n",
    "    def run_comprehensive_test(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run all available tests and return comprehensive results.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing all test results\n",
    "        \"\"\"\n",
    "        print(\"üß™ Starting comprehensive voice agent tests...\\n\")\n",
    "        \n",
    "        # Test 1: Configuration\n",
    "        print(\"üìã Testing Configuration...\")\n",
    "        self.test_results[\"configuration\"] = self.test_configuration()\n",
    "        \n",
    "        # Test 2: Audio Components\n",
    "        print(\"\\nüé§ Testing Audio Components...\")\n",
    "        self.test_results[\"audio\"] = self.test_audio_components()\n",
    "        \n",
    "        # Test 3: DeepSeek API\n",
    "        print(\"\\nü§ñ Testing DeepSeek API...\")\n",
    "        self.test_results[\"deepseek_api\"] = self.test_deepseek_api()\n",
    "        \n",
    "        # Test 4: MCP Protocol\n",
    "        print(\"\\nüì° Testing MCP Protocol...\")\n",
    "        self.test_results[\"mcp_protocol\"] = self.test_mcp_protocol()\n",
    "        \n",
    "        # Test 5: Integration\n",
    "        print(\"\\nüîó Testing Component Integration...\")\n",
    "        self.test_results[\"integration\"] = self.test_integration()\n",
    "        \n",
    "        # Generate summary\n",
    "        self.test_results[\"summary\"] = self.generate_test_summary()\n",
    "        \n",
    "        print(\"\\n‚úÖ Comprehensive testing completed!\")\n",
    "        return self.test_results\n",
    "    \n",
    "    def test_configuration(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test configuration validity.\n",
    "        \n",
    "        Returns:\n",
    "            Configuration test results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"api_key_set\": False,\n",
    "            \"audio_config_valid\": False,\n",
    "            \"model_config_valid\": False,\n",
    "            \"issues\": []\n",
    "        }\n",
    "        \n",
    "        config = self.voice_agent.config\n",
    "        \n",
    "        # Check API key\n",
    "        if config.DEEPSEEK_API_KEY != \"your-deepseek-api-key-here\":\n",
    "            results[\"api_key_set\"] = True\n",
    "            print(\"  ‚úÖ DeepSeek API key is configured\")\n",
    "        else:\n",
    "            results[\"issues\"].append(\"DeepSeek API key not set\")\n",
    "            print(\"  ‚ùå DeepSeek API key not configured\")\n",
    "        \n",
    "        # Check audio configuration\n",
    "        if config.SAMPLE_RATE > 0 and config.ENERGY_THRESHOLD > 0:\n",
    "            results[\"audio_config_valid\"] = True\n",
    "            print(\"  ‚úÖ Audio configuration valid\")\n",
    "        else:\n",
    "            results[\"issues\"].append(\"Invalid audio configuration\")\n",
    "            print(\"  ‚ùå Invalid audio configuration\")\n",
    "        \n",
    "        # Check model configuration\n",
    "        if config.MODEL_NAME and config.MAX_TOKENS > 0:\n",
    "            results[\"model_config_valid\"] = True\n",
    "            print(\"  ‚úÖ Model configuration valid\")\n",
    "        else:\n",
    "            results[\"issues\"].append(\"Invalid model configuration\")\n",
    "            print(\"  ‚ùå Invalid model configuration\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_audio_components(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test audio input/output components.\n",
    "        \n",
    "        Returns:\n",
    "            Audio component test results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"microphone_available\": False,\n",
    "            \"tts_available\": False,\n",
    "            \"calibration_successful\": False,\n",
    "            \"issues\": []\n",
    "        }\n",
    "        \n",
    "        audio_test = self.voice_agent.audio_processor.test_audio_devices()\n",
    "        \n",
    "        # Check microphone\n",
    "        if audio_test[\"microphone\"]:\n",
    "            results[\"microphone_available\"] = True\n",
    "            print(\"  ‚úÖ Microphone available and working\")\n",
    "        else:\n",
    "            results[\"issues\"].append(f\"Microphone issue: {audio_test['details']['microphone']}\")\n",
    "            print(f\"  ‚ùå Microphone problem: {audio_test['details']['microphone']}\")\n",
    "        \n",
    "        # Check text-to-speech\n",
    "        if audio_test[\"speakers\"]:\n",
    "            results[\"tts_available\"] = True\n",
    "            print(\"  ‚úÖ Text-to-speech available and working\")\n",
    "        else:\n",
    "            results[\"issues\"].append(f\"TTS issue: {audio_test['details']['speakers']}\")\n",
    "            print(f\"  ‚ùå Text-to-speech problem: {audio_test['details']['speakers']}\")\n",
    "        \n",
    "        # Check calibration\n",
    "        try:\n",
    "            energy_threshold = self.voice_agent.audio_processor.recognizer.energy_threshold\n",
    "            if energy_threshold > 0:\n",
    "                results[\"calibration_successful\"] = True\n",
    "                print(f\"  ‚úÖ Microphone calibrated (threshold: {energy_threshold})\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Microphone calibration failed\")\n",
    "                print(\"  ‚ùå Microphone calibration failed\")\n",
    "        except Exception as e:\n",
    "            results[\"issues\"].append(f\"Calibration error: {str(e)}\")\n",
    "            print(f\"  ‚ùå Calibration error: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_deepseek_api(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test DeepSeek API connectivity and functionality.\n",
    "        \n",
    "        Returns:\n",
    "            DeepSeek API test results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"connection_successful\": False,\n",
    "            \"response_generation\": False,\n",
    "            \"response_quality\": False,\n",
    "            \"response_time\": 0,\n",
    "            \"issues\": []\n",
    "        }\n",
    "        \n",
    "        # Test basic connection\n",
    "        connection_test = self.voice_agent.deepseek_client.test_connection()\n",
    "        if connection_test:\n",
    "            results[\"connection_successful\"] = True\n",
    "            print(\"  ‚úÖ DeepSeek API connection successful\")\n",
    "        else:\n",
    "            results[\"issues\"].append(\"Cannot connect to DeepSeek API\")\n",
    "            print(\"  ‚ùå DeepSeek API connection failed\")\n",
    "            return results\n",
    "        \n",
    "        # Test response generation\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Use asyncio.run for testing async function\n",
    "            test_response = asyncio.run(\n",
    "                self.voice_agent.deepseek_client.generate_response(\n",
    "                    \"Hello, this is a test message. Please respond briefly.\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            results[\"response_time\"] = time.time() - start_time\n",
    "            \n",
    "            if test_response and len(test_response) > 0:\n",
    "                results[\"response_generation\"] = True\n",
    "                print(f\"  ‚úÖ Response generation successful ({results['response_time']:.2f}s)\")\n",
    "                \n",
    "                # Basic quality check\n",
    "                if len(test_response) > 10 and not test_response.startswith(\"I'm sorry\"):\n",
    "                    results[\"response_quality\"] = True\n",
    "                    print(f\"  ‚úÖ Response quality good: '{test_response[:50]}...'\")\n",
    "                else:\n",
    "                    results[\"issues\"].append(\"Response quality concerns\")\n",
    "                    print(f\"  ‚ö†Ô∏è  Response quality concerns: '{test_response[:50]}...'\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Empty or invalid response\")\n",
    "                print(\"  ‚ùå Empty or invalid response\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[\"issues\"].append(f\"Response generation error: {str(e)}\")\n",
    "            print(f\"  ‚ùå Response generation error: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_mcp_protocol(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test MCP protocol functionality.\n",
    "        \n",
    "        Returns:\n",
    "            MCP protocol test results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"request_creation\": False,\n",
    "            \"response_processing\": False,\n",
    "            \"context_management\": False,\n",
    "            \"issues\": []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Test request creation\n",
    "            test_request = self.voice_agent.mcp.create_request(\"Test message\")\n",
    "            if all(key in test_request for key in [\"mcp_version\", \"session_id\", \"user_input\"]):\n",
    "                results[\"request_creation\"] = True\n",
    "                print(\"  ‚úÖ MCP request creation successful\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Invalid MCP request structure\")\n",
    "                print(\"  ‚ùå Invalid MCP request structure\")\n",
    "            \n",
    "            # Test response processing\n",
    "            test_response = self.voice_agent.mcp.process_response(\n",
    "                \"Test response\", \n",
    "                test_request[\"request_id\"]\n",
    "            )\n",
    "            if all(key in test_response for key in [\"mcp_version\", \"session_id\", \"response\"]):\n",
    "                results[\"response_processing\"] = True\n",
    "                print(\"  ‚úÖ MCP response processing successful\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Invalid MCP response structure\")\n",
    "                print(\"  ‚ùå Invalid MCP response structure\")\n",
    "            \n",
    "            # Test context management\n",
    "            context_summary = self.voice_agent.mcp.get_context_summary()\n",
    "            if isinstance(context_summary, str):\n",
    "                results[\"context_management\"] = True\n",
    "                print(\"  ‚úÖ MCP context management working\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Context management error\")\n",
    "                print(\"  ‚ùå Context management error\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[\"issues\"].append(f\"MCP protocol error: {str(e)}\")\n",
    "            print(f\"  ‚ùå MCP protocol error: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_integration(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test integration between all components.\n",
    "        \n",
    "        Returns:\n",
    "            Integration test results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"text_processing_flow\": False,\n",
    "            \"session_management\": False,\n",
    "            \"error_handling\": False,\n",
    "            \"issues\": []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Test text processing flow (without actual speech)\n",
    "            print(\"  üîÑ Testing text processing flow...\")\n",
    "            \n",
    "            # Create a mock MCP request\n",
    "            mock_request = self.voice_agent.mcp.create_request(\"Hello, how are you?\")\n",
    "            \n",
    "            # Generate response using DeepSeek (if API is available)\n",
    "            if self.test_results.get(\"deepseek_api\", {}).get(\"connection_successful\"):\n",
    "                mock_response = asyncio.run(\n",
    "                    self.voice_agent.deepseek_client.generate_response(\n",
    "                        \"Hello, how are you?\",\n",
    "                        self.voice_agent.mcp.context_history\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Process response through MCP\n",
    "                mcp_response = self.voice_agent.mcp.process_response(\n",
    "                    mock_response,\n",
    "                    mock_request[\"request_id\"]\n",
    "                )\n",
    "                \n",
    "                if mcp_response and mock_response:\n",
    "                    results[\"text_processing_flow\"] = True\n",
    "                    print(\"    ‚úÖ Text processing flow successful\")\n",
    "                else:\n",
    "                    results[\"issues\"].append(\"Text processing flow failed\")\n",
    "                    print(\"    ‚ùå Text processing flow failed\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Skipping text flow test - API unavailable\")\n",
    "                print(\"    ‚ö†Ô∏è  Skipping text flow test - API unavailable\")\n",
    "            \n",
    "            # Test session management\n",
    "            session_stats = self.voice_agent.get_session_stats()\n",
    "            if session_stats and \"session_id\" in session_stats:\n",
    "                results[\"session_management\"] = True\n",
    "                print(\"    ‚úÖ Session management working\")\n",
    "            else:\n",
    "                results[\"issues\"].append(\"Session management error\")\n",
    "                print(\"    ‚ùå Session management error\")\n",
    "            \n",
    "            # Test error handling\n",
    "            try:\n",
    "                # Try to create an invalid request\n",
    "                error_response = asyncio.run(\n",
    "                    self.voice_agent.deepseek_client.generate_response(\"\")\n",
    "                )\n",
    "                # If we get here without exception, error handling is working\n",
    "                results[\"error_handling\"] = True\n",
    "                print(\"    ‚úÖ Error handling working\")\n",
    "            except Exception:\n",
    "                # This is expected - we want graceful error handling\n",
    "                results[\"error_handling\"] = True\n",
    "                print(\"    ‚úÖ Error handling working (graceful exception)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[\"issues\"].append(f\"Integration test error: {str(e)}\")\n",
    "            print(f\"    ‚ùå Integration test error: {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_test_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate a summary of all test results.\n",
    "        \n",
    "        Returns:\n",
    "            Test summary\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            \"total_tests\": 0,\n",
    "            \"passed_tests\": 0,\n",
    "            \"failed_tests\": 0,\n",
    "            \"warnings\": 0,\n",
    "            \"overall_status\": \"unknown\",\n",
    "            \"critical_issues\": [],\n",
    "            \"recommendations\": []\n",
    "        }\n",
    "        \n",
    "        # Count tests and issues\n",
    "        for category, results in self.test_results.items():\n",
    "            if category == \"summary\":\n",
    "                continue\n",
    "                \n",
    "            if isinstance(results, dict):\n",
    "                for key, value in results.items():\n",
    "                    if isinstance(value, bool):\n",
    "                        summary[\"total_tests\"] += 1\n",
    "                        if value:\n",
    "                            summary[\"passed_tests\"] += 1\n",
    "                        else:\n",
    "                            summary[\"failed_tests\"] += 1\n",
    "                \n",
    "                # Collect critical issues\n",
    "                if \"issues\" in results:\n",
    "                    summary[\"critical_issues\"].extend(results[\"issues\"])\n",
    "        \n",
    "        # Determine overall status\n",
    "        if summary[\"failed_tests\"] == 0:\n",
    "            summary[\"overall_status\"] = \"excellent\"\n",
    "        elif summary[\"passed_tests\"] > summary[\"failed_tests\"]:\n",
    "            summary[\"overall_status\"] = \"good\"\n",
    "        else:\n",
    "            summary[\"overall_status\"] = \"needs_attention\"\n",
    "        \n",
    "        # Generate recommendations\n",
    "        if not self.test_results.get(\"configuration\", {}).get(\"api_key_set\"):\n",
    "            summary[\"recommendations\"].append(\"Set DEEPSEEK_API_KEY environment variable\")\n",
    "        \n",
    "        if not self.test_results.get(\"audio\", {}).get(\"microphone_available\"):\n",
    "            summary[\"recommendations\"].append(\"Check microphone permissions and hardware\")\n",
    "        \n",
    "        if not self.test_results.get(\"audio\", {}).get(\"tts_available\"):\n",
    "            summary[\"recommendations\"].append(\"Check audio output devices and drivers\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"\n",
    "        Print a formatted test summary.\n",
    "        \"\"\"\n",
    "        if \"summary\" not in self.test_results:\n",
    "            print(\"‚ùå No test results available. Run tests first.\")\n",
    "            return\n",
    "        \n",
    "        summary = self.test_results[\"summary\"]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üß™ VOICE AGENT TEST SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Overall status\n",
    "        status_emoji = {\n",
    "            \"excellent\": \"üü¢\",\n",
    "            \"good\": \"üü°\", \n",
    "            \"needs_attention\": \"üî¥\",\n",
    "            \"unknown\": \"‚ö™\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Overall Status: {status_emoji[summary['overall_status']]} {summary['overall_status'].replace('_', ' ').title()}\")\n",
    "        print(f\"Tests Passed: {summary['passed_tests']}/{summary['total_tests']}\")\n",
    "        \n",
    "        # Critical issues\n",
    "        if summary[\"critical_issues\"]:\n",
    "            print(\"\\nüö® Critical Issues:\")\n",
    "            for issue in summary[\"critical_issues\"]:\n",
    "                print(f\"  ‚Ä¢ {issue}\")\n",
    "        \n",
    "        # Recommendations\n",
    "        if summary[\"recommendations\"]:\n",
    "            print(\"\\nüí° Recommendations:\")\n",
    "            for rec in summary[\"recommendations\"]:\n",
    "                print(f\"  ‚Ä¢ {rec}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Initialize tester\n",
    "tester = VoiceAgentTester(voice_agent)\n",
    "\n",
    "print(\"‚úÖ Voice Agent Tester initialized\")\n",
    "print(\"üß™ Use tester.run_comprehensive_test() to run all tests\")\n",
    "print(\"üìä Use tester.print_summary() to see test results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-tests-section",
   "metadata": {},
   "source": [
    "### Run Comprehensive Tests\n",
    "\n",
    "Execute this cell to run all tests and get a comprehensive health check of your voice agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-tests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive tests\n",
    "test_results = tester.run_comprehensive_test()\n",
    "\n",
    "# Print formatted summary\n",
    "tester.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "troubleshooting-section",
   "metadata": {},
   "source": [
    "## 10. Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### üé§ Audio Issues\n",
    "\n",
    "**Problem**: Microphone not working or poor recognition\n",
    "- **Solution**: Check microphone permissions in your browser/system\n",
    "- **Solution**: Adjust energy threshold: `audio_processor.recognizer.energy_threshold = 500`\n",
    "- **Solution**: Test with different microphones or audio devices\n",
    "\n",
    "**Problem**: No sound output from text-to-speech\n",
    "- **Solution**: Check system audio settings and volume\n",
    "- **Solution**: Try different TTS voices: modify `config.TTS_VOICE_INDEX`\n",
    "- **Solution**: Restart the audio processor: `audio_processor = AudioProcessor(config)`\n",
    "\n",
    "#### ü§ñ API Issues\n",
    "\n",
    "**Problem**: DeepSeek API connection failed\n",
    "- **Solution**: Verify API key is correctly set in environment variables\n",
    "- **Solution**: Check internet connection and firewall settings\n",
    "- **Solution**: Verify API endpoint URL is correct\n",
    "\n",
    "**Problem**: API rate limiting or quota exceeded\n",
    "- **Solution**: Add delays between requests\n",
    "- **Solution**: Implement request queuing and retry logic\n",
    "- **Solution**: Check your API usage limits\n",
    "\n",
    "#### üì° MCP Issues\n",
    "\n",
    "**Problem**: Context not maintained between interactions\n",
    "- **Solution**: Check MCP session management: `mcp.context_history`\n",
    "- **Solution**: Verify request/response processing\n",
    "- **Solution**: Restart MCP protocol: `mcp = MCPProtocol(config)`\n",
    "\n",
    "#### üîß Performance Issues\n",
    "\n",
    "**Problem**: Slow response times\n",
    "- **Solution**: Reduce `config.MAX_TOKENS` for faster responses\n",
    "- **Solution**: Optimize speech recognition timeout settings\n",
    "- **Solution**: Use faster TTS settings: increase `config.TTS_RATE`\n",
    "\n",
    "### Environment-Specific Solutions\n",
    "\n",
    "#### Linux/Ubuntu\n",
    "```bash\n",
    "# Install audio dependencies\n",
    "sudo apt-get install portaudio19-dev python3-pyaudio\n",
    "sudo apt-get install espeak espeak-data libespeak-dev\n",
    "```\n",
    "\n",
    "#### macOS\n",
    "```bash\n",
    "# Install audio dependencies\n",
    "brew install portaudio\n",
    "pip install pyaudio\n",
    "```\n",
    "\n",
    "#### Windows\n",
    "```bash\n",
    "# PyAudio wheel installation\n",
    "pip install pipwin\n",
    "pipwin install pyaudio\n",
    "```\n",
    "\n",
    "### Debug Mode\n",
    "\n",
    "Enable verbose logging for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debug-mode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable debug logging\n",
    "import logging\n",
    "\n",
    "# Set logging level to DEBUG for detailed information\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    force=True  # Override existing configuration\n",
    ")\n",
    "\n",
    "print(\"üêõ Debug mode enabled\")\n",
    "print(\"üìù All operations will now show detailed logging information\")\n",
    "print(\"üí° To disable debug mode, restart the kernel or set level to INFO\")\n",
    "\n",
    "# Test debug logging\n",
    "logger.debug(\"Debug mode test message\")\n",
    "logger.info(\"Info level message\")\n",
    "logger.warning(\"Warning level message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-examples-section",
   "metadata": {},
   "source": [
    "## 11. Usage Examples and Best Practices\n",
    "\n",
    "### Example Conversation Flows\n",
    "\n",
    "Here are some example interactions you can try with your voice agent:\n",
    "\n",
    "#### üéØ Simple Q&A\n",
    "- **You**: \"What's the weather like today?\"\n",
    "- **Agent**: \"I don't have access to real-time weather data, but I can help you understand how to check the weather or discuss weather-related topics.\"\n",
    "\n",
    "#### üí° Creative Tasks\n",
    "- **You**: \"Write a short poem about technology\"\n",
    "- **Agent**: [Generates creative poem]\n",
    "\n",
    "#### üßÆ Problem Solving\n",
    "- **You**: \"Explain how machine learning works\"\n",
    "- **Agent**: [Provides clear explanation suitable for voice]\n",
    "\n",
    "#### üéì Learning Assistant\n",
    "- **You**: \"Help me understand Python functions\"\n",
    "- **Agent**: [Explains programming concepts conversationally]\n",
    "\n",
    "### Best Practices for Voice Interaction\n",
    "\n",
    "#### For Users:\n",
    "1. **Speak clearly** and at a moderate pace\n",
    "2. **Use a quiet environment** to reduce background noise\n",
    "3. **Be specific** in your questions for better responses\n",
    "4. **Wait for the agent** to finish speaking before responding\n",
    "5. **Use keywords** like \"goodbye\" or \"stop\" to end conversations\n",
    "\n",
    "#### For Developers:\n",
    "1. **Calibrate microphone** regularly for optimal recognition\n",
    "2. **Monitor API usage** to avoid rate limits\n",
    "3. **Implement error handling** for robust operation\n",
    "4. **Test in different environments** for reliability\n",
    "5. **Keep responses concise** for better voice experience\n",
    "\n",
    "### Advanced Configuration Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-config-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Custom configuration for different use cases\n",
    "\n",
    "def create_presentation_config():\n",
    "    \"\"\"\n",
    "    Configuration optimized for presentation mode.\n",
    "    - Slower speech rate for clarity\n",
    "    - Higher energy threshold for noisy environments\n",
    "    - Shorter responses for engagement\n",
    "    \"\"\"\n",
    "    config = VoiceAgentConfig()\n",
    "    config.TTS_RATE = 150  # Slower speech\n",
    "    config.ENERGY_THRESHOLD = 500  # Higher threshold\n",
    "    config.MAX_TOKENS = 500  # Shorter responses\n",
    "    config.TEMPERATURE = 0.5  # More focused responses\n",
    "    return config\n",
    "\n",
    "def create_casual_config():\n",
    "    \"\"\"\n",
    "    Configuration optimized for casual conversation.\n",
    "    - Natural speech rate\n",
    "    - Creative responses\n",
    "    - Longer interaction timeout\n",
    "    \"\"\"\n",
    "    config = VoiceAgentConfig()\n",
    "    config.TTS_RATE = 200  # Normal speech\n",
    "    config.ENERGY_THRESHOLD = 300  # Standard threshold\n",
    "    config.MAX_TOKENS = 800  # Longer responses\n",
    "    config.TEMPERATURE = 0.8  # More creative\n",
    "    config.RECOGNITION_TIMEOUT = 10  # Longer timeout\n",
    "    return config\n",
    "\n",
    "def create_accessibility_config():\n",
    "    \"\"\"\n",
    "    Configuration optimized for accessibility.\n",
    "    - Very clear speech\n",
    "    - Patient interaction timing\n",
    "    - Detailed responses\n",
    "    \"\"\"\n",
    "    config = VoiceAgentConfig()\n",
    "    config.TTS_RATE = 120  # Very slow speech\n",
    "    config.TTS_VOLUME = 1.0  # Maximum volume\n",
    "    config.RECOGNITION_TIMEOUT = 15  # Very patient\n",
    "    config.PHRASE_TIMEOUT = 2  # Longer pause tolerance\n",
    "    config.MAX_TOKENS = 600  # Detailed responses\n",
    "    return config\n",
    "\n",
    "# Example usage:\n",
    "print(\"üìã Configuration Examples Created:\")\n",
    "print(\"  üé§ Presentation Mode: create_presentation_config()\")\n",
    "print(\"  üí¨ Casual Mode: create_casual_config()\")\n",
    "print(\"  ‚ôø Accessibility Mode: create_accessibility_config()\")\n",
    "\n",
    "# To use a different configuration:\n",
    "# new_config = create_presentation_config()\n",
    "# new_voice_agent = VoiceAgent(new_config, MCPProtocol(new_config), \n",
    "#                              DeepSeekClient(new_config), AudioProcessor(new_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section",
   "metadata": {},
   "source": [
    "## 12. Conclusion and Next Steps\n",
    "\n",
    "### üéâ Congratulations!\n",
    "\n",
    "You have successfully set up and configured a comprehensive MCP-powered voice agent with DeepSeek integration. This implementation includes:\n",
    "\n",
    "‚úÖ **Complete Voice Pipeline**: Speech recognition ‚Üí AI processing ‚Üí Text-to-speech  \n",
    "‚úÖ **MCP Protocol Integration**: Structured communication and context management  \n",
    "‚úÖ **DeepSeek AI Model**: Advanced language understanding and generation  \n",
    "‚úÖ **Interactive Interface**: User-friendly Jupyter widget controls  \n",
    "‚úÖ **Comprehensive Testing**: Automated health checks and diagnostics  \n",
    "‚úÖ **Detailed Documentation**: Extensive code comments and explanations  \n",
    "\n",
    "### üöÄ Next Steps for Enhancement\n",
    "\n",
    "#### Immediate Improvements:\n",
    "1. **Add wake word detection** for hands-free activation\n",
    "2. **Implement conversation memory** across sessions\n",
    "3. **Add multi-language support** for global accessibility\n",
    "4. **Create custom voice commands** for specific actions\n",
    "\n",
    "#### Advanced Features:\n",
    "1. **Integration with external APIs** (weather, news, calendar)\n",
    "2. **Voice emotion detection** for more natural responses\n",
    "3. **Streaming responses** for faster interaction\n",
    "4. **Voice cloning** for personalized TTS\n",
    "\n",
    "#### Production Deployment:\n",
    "1. **Add authentication and security**\n",
    "2. **Implement rate limiting and monitoring**\n",
    "3. **Create web interface** for broader accessibility\n",
    "4. **Add cloud deployment options**\n",
    "\n",
    "### üìö Learning Resources\n",
    "\n",
    "- **MCP Documentation**: Learn more about Model Context Protocol\n",
    "- **DeepSeek API Docs**: Explore advanced model capabilities\n",
    "- **Speech Recognition**: Dive deeper into audio processing\n",
    "- **Jupyter Widgets**: Create more interactive interfaces\n",
    "\n",
    "### ü§ù Community and Support\n",
    "\n",
    "- Share your voice agent implementations\n",
    "- Contribute improvements and bug fixes\n",
    "- Help others troubleshoot common issues\n",
    "- Explore creative use cases and applications\n",
    "\n",
    "### üí° Final Tips\n",
    "\n",
    "1. **Start with the testing suite** to ensure everything works\n",
    "2. **Experiment with different configurations** for your use case\n",
    "3. **Monitor API usage** to manage costs effectively\n",
    "4. **Keep your environment updated** for security and performance\n",
    "5. **Document your customizations** for future reference\n",
    "\n",
    "---\n",
    "\n",
    "**Happy voice agent building!** üé§ü§ñ‚ú®\n",
    "\n",
    "*Remember: This is a powerful tool - use it responsibly and respect user privacy and consent when processing voice data.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
